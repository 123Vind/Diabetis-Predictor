{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetisNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqUQXtpdW8cQsHuyrupdFM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123Vind/Diabetis-Predictor/blob/master/diabetisNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz1oFLk2uDOn",
        "outputId": "7f15a763-2f70-46db-94a8-cbb27c13199d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Dv7LAgIW8023"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dataset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRRg-Yy_989m",
        "outputId": "1b0da26f-77b6-4f69-d6e4-99ab6a0bd125"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetis =  pd.read_csv('/content/drive/My Drive/Colab Notebooks/diabetis.csv',header = None)"
      ],
      "metadata": {
        "id": "5mQ3rEFd8_X2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetis.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRXo_4T7-OPi",
        "outputId": "956c965a-9d95-42e1-a4cf-017db120eb9c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of       0    1   2   3    4     5      6   7  8\n",
              "0     6  148  72  35    0  33.6  0.627  50  1\n",
              "1     1   85  66  29    0  26.6  0.351  31  0\n",
              "2     8  183  64   0    0  23.3  0.672  32  1\n",
              "3     1   89  66  23   94  28.1  0.167  21  0\n",
              "4     0  137  40  35  168  43.1  2.288  33  1\n",
              "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
              "763  10  101  76  48  180  32.9  0.171  63  0\n",
              "764   2  122  70  27    0  36.8  0.340  27  0\n",
              "765   5  121  72  23  112  26.2  0.245  30  0\n",
              "766   1  126  60   0    0  30.1  0.349  47  1\n",
              "767   1   93  70  31    0  30.4  0.315  23  0\n",
              "\n",
              "[768 rows x 9 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = diabetis.iloc[:,:-1]\n",
        "y = diabetis.iloc[:,-1]\n"
      ],
      "metadata": {
        "id": "Wr4e-b21-RNS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling the training data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "bsabFBPZLc90"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZyFg5Cb--pzY",
        "outputId": "18c888f7-84c7-4471-9b4e-eaef9eeed057"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0    1   2   3    4     5      6   7\n",
              "0     6  148  72  35    0  33.6  0.627  50\n",
              "1     1   85  66  29    0  26.6  0.351  31\n",
              "2     8  183  64   0    0  23.3  0.672  32\n",
              "3     1   89  66  23   94  28.1  0.167  21\n",
              "4     0  137  40  35  168  43.1  2.288  33\n",
              "..   ..  ...  ..  ..  ...   ...    ...  ..\n",
              "763  10  101  76  48  180  32.9  0.171  63\n",
              "764   2  122  70  27    0  36.8  0.340  27\n",
              "765   5  121  72  23  112  26.2  0.245  30\n",
              "766   1  126  60   0    0  30.1  0.349  47\n",
              "767   1   93  70  31    0  30.4  0.315  23\n",
              "\n",
              "[768 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cf84f97-c8bb-495c-afff-00df6460300c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cf84f97-c8bb-495c-afff-00df6460300c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7cf84f97-c8bb-495c-afff-00df6460300c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7cf84f97-c8bb-495c-afff-00df6460300c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y.value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8QxEBeX-rjh",
        "outputId": "bab473b9-a7d3-4547-f4a9-7a4577ce7cf8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    500\n",
              "1    268\n",
              "Name: 8, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xfWl-YL6y6D4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to get rid of the unbalanced class\n",
        "oversample = SMOTE()\n",
        "X_res, y_res = oversample.fit_resample(X_scaled, y)\n",
        "#tl = TomekLinks(sampling_strategy=0.5)\n",
        "#X_res, y_res = tl.fit_resample(X,y)"
      ],
      "metadata": {
        "id": "cEL0Mjp82F_4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,random_state = 2,test_size = 0.25,stratify = y_res)"
      ],
      "metadata": {
        "id": "KJpZg6H_-zSV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d4wrar2_Qrx",
        "outputId": "dc2e9a8c-7094-4848-a39e-1155ad09ba33"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17647059, 0.71356784, 0.6557377 , ..., 0.4828614 , 0.05209223,\n",
              "        0.7       ],\n",
              "       [0.41176471, 0.71356784, 0.73770492, ..., 0.45305514, 0.02134927,\n",
              "        0.36666667],\n",
              "       [0.35294118, 0.67336683, 0.6557377 , ..., 0.68852459, 0.06831768,\n",
              "        0.41666667],\n",
              "       ...,\n",
              "       [0.11764706, 0.50753769, 0.47540984, ..., 0.32488823, 0.03287788,\n",
              "        0.01666667],\n",
              "       [0.29411765, 0.49748744, 0.60655738, ..., 0.43219076, 0.05337319,\n",
              "        0.18333333],\n",
              "       [0.1137984 , 0.72263175, 0.47594612, ..., 0.4724015 , 0.14844745,\n",
              "        0.06448576]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_res.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQty7brxvf3S",
        "outputId": "4ff2b61a-0b4f-4160-816b-f237553a1583"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "0    500\n",
              "Name: 8, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0RZN3kr_U5Z",
        "outputId": "7a2cec16-41e8-4693-b5e3-a69098d29d01"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "MPRHKNb3_Yc_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQypVnm4_upX",
        "outputId": "89b0bd13-81e2-4840-af7f-60abff90633a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(6,input_dim=8,activation='relu'))\n",
        "  model.add(Dense(8,activation='relu'))\n",
        "  model.add(Dense(12,activation='relu'))\n",
        "  model.add(Dense(10,activation='relu'))\n",
        "  model.add(Dense(num_classes,activation='sigmoid'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "yp0E6L3a_w2P"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "RgPpDMvTAmg2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01O_0yDhVs33",
        "outputId": "cc14f109-af75-4f56-aa5f-94a0b5d66ecd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAsH2G_zWs-x",
        "outputId": "655dd4b8-2ed8-4051-9e61-10c7cf752bbb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "sample_weight = np.ones(shape=(len(y_train),2))\n",
        "#sample_weight.shape\n",
        "sample_weight[y_train==[0.,1.] ] = 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTs_rDjNArC_",
        "outputId": "9c963b0d-25fa-4c6d-d6ce-5fdbc536b693"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 56        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 12)                108       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                130       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 370\n",
            "Trainable params: 370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=500,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5gDNKSVAtOA",
        "outputId": "274ab7f8-99ea-41e3-d768-5ffcd0157c9c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "24/24 - 1s - loss: 0.6890 - accuracy: 0.5813 - 550ms/epoch - 23ms/step\n",
            "Epoch 2/500\n",
            "24/24 - 0s - loss: 0.6852 - accuracy: 0.5013 - 56ms/epoch - 2ms/step\n",
            "Epoch 3/500\n",
            "24/24 - 0s - loss: 0.6813 - accuracy: 0.5040 - 52ms/epoch - 2ms/step\n",
            "Epoch 4/500\n",
            "24/24 - 0s - loss: 0.6772 - accuracy: 0.5160 - 58ms/epoch - 2ms/step\n",
            "Epoch 5/500\n",
            "24/24 - 0s - loss: 0.6697 - accuracy: 0.6320 - 59ms/epoch - 2ms/step\n",
            "Epoch 6/500\n",
            "24/24 - 0s - loss: 0.6594 - accuracy: 0.6453 - 62ms/epoch - 3ms/step\n",
            "Epoch 7/500\n",
            "24/24 - 0s - loss: 0.6433 - accuracy: 0.6880 - 56ms/epoch - 2ms/step\n",
            "Epoch 8/500\n",
            "24/24 - 0s - loss: 0.6264 - accuracy: 0.6867 - 60ms/epoch - 3ms/step\n",
            "Epoch 9/500\n",
            "24/24 - 0s - loss: 0.6152 - accuracy: 0.6907 - 71ms/epoch - 3ms/step\n",
            "Epoch 10/500\n",
            "24/24 - 0s - loss: 0.5979 - accuracy: 0.6933 - 49ms/epoch - 2ms/step\n",
            "Epoch 11/500\n",
            "24/24 - 0s - loss: 0.5840 - accuracy: 0.6987 - 40ms/epoch - 2ms/step\n",
            "Epoch 12/500\n",
            "24/24 - 0s - loss: 0.5754 - accuracy: 0.7133 - 58ms/epoch - 2ms/step\n",
            "Epoch 13/500\n",
            "24/24 - 0s - loss: 0.5621 - accuracy: 0.7187 - 38ms/epoch - 2ms/step\n",
            "Epoch 14/500\n",
            "24/24 - 0s - loss: 0.5460 - accuracy: 0.7267 - 49ms/epoch - 2ms/step\n",
            "Epoch 15/500\n",
            "24/24 - 0s - loss: 0.5363 - accuracy: 0.7307 - 56ms/epoch - 2ms/step\n",
            "Epoch 16/500\n",
            "24/24 - 0s - loss: 0.5293 - accuracy: 0.7253 - 41ms/epoch - 2ms/step\n",
            "Epoch 17/500\n",
            "24/24 - 0s - loss: 0.5300 - accuracy: 0.7307 - 37ms/epoch - 2ms/step\n",
            "Epoch 18/500\n",
            "24/24 - 0s - loss: 0.5174 - accuracy: 0.7360 - 39ms/epoch - 2ms/step\n",
            "Epoch 19/500\n",
            "24/24 - 0s - loss: 0.5088 - accuracy: 0.7493 - 39ms/epoch - 2ms/step\n",
            "Epoch 20/500\n",
            "24/24 - 0s - loss: 0.5030 - accuracy: 0.7453 - 39ms/epoch - 2ms/step\n",
            "Epoch 21/500\n",
            "24/24 - 0s - loss: 0.5030 - accuracy: 0.7413 - 41ms/epoch - 2ms/step\n",
            "Epoch 22/500\n",
            "24/24 - 0s - loss: 0.4966 - accuracy: 0.7640 - 40ms/epoch - 2ms/step\n",
            "Epoch 23/500\n",
            "24/24 - 0s - loss: 0.4915 - accuracy: 0.7507 - 37ms/epoch - 2ms/step\n",
            "Epoch 24/500\n",
            "24/24 - 0s - loss: 0.4900 - accuracy: 0.7653 - 40ms/epoch - 2ms/step\n",
            "Epoch 25/500\n",
            "24/24 - 0s - loss: 0.4927 - accuracy: 0.7587 - 47ms/epoch - 2ms/step\n",
            "Epoch 26/500\n",
            "24/24 - 0s - loss: 0.4873 - accuracy: 0.7680 - 51ms/epoch - 2ms/step\n",
            "Epoch 27/500\n",
            "24/24 - 0s - loss: 0.4924 - accuracy: 0.7653 - 49ms/epoch - 2ms/step\n",
            "Epoch 28/500\n",
            "24/24 - 0s - loss: 0.4847 - accuracy: 0.7680 - 44ms/epoch - 2ms/step\n",
            "Epoch 29/500\n",
            "24/24 - 0s - loss: 0.4808 - accuracy: 0.7667 - 46ms/epoch - 2ms/step\n",
            "Epoch 30/500\n",
            "24/24 - 0s - loss: 0.4796 - accuracy: 0.7627 - 36ms/epoch - 2ms/step\n",
            "Epoch 31/500\n",
            "24/24 - 0s - loss: 0.4800 - accuracy: 0.7573 - 40ms/epoch - 2ms/step\n",
            "Epoch 32/500\n",
            "24/24 - 0s - loss: 0.4760 - accuracy: 0.7680 - 40ms/epoch - 2ms/step\n",
            "Epoch 33/500\n",
            "24/24 - 0s - loss: 0.4750 - accuracy: 0.7720 - 44ms/epoch - 2ms/step\n",
            "Epoch 34/500\n",
            "24/24 - 0s - loss: 0.4746 - accuracy: 0.7653 - 35ms/epoch - 1ms/step\n",
            "Epoch 35/500\n",
            "24/24 - 0s - loss: 0.4814 - accuracy: 0.7640 - 39ms/epoch - 2ms/step\n",
            "Epoch 36/500\n",
            "24/24 - 0s - loss: 0.4737 - accuracy: 0.7720 - 36ms/epoch - 2ms/step\n",
            "Epoch 37/500\n",
            "24/24 - 0s - loss: 0.4782 - accuracy: 0.7773 - 53ms/epoch - 2ms/step\n",
            "Epoch 38/500\n",
            "24/24 - 0s - loss: 0.4748 - accuracy: 0.7680 - 38ms/epoch - 2ms/step\n",
            "Epoch 39/500\n",
            "24/24 - 0s - loss: 0.4725 - accuracy: 0.7720 - 41ms/epoch - 2ms/step\n",
            "Epoch 40/500\n",
            "24/24 - 0s - loss: 0.4735 - accuracy: 0.7653 - 40ms/epoch - 2ms/step\n",
            "Epoch 41/500\n",
            "24/24 - 0s - loss: 0.4730 - accuracy: 0.7613 - 39ms/epoch - 2ms/step\n",
            "Epoch 42/500\n",
            "24/24 - 0s - loss: 0.4688 - accuracy: 0.7720 - 48ms/epoch - 2ms/step\n",
            "Epoch 43/500\n",
            "24/24 - 0s - loss: 0.4707 - accuracy: 0.7720 - 51ms/epoch - 2ms/step\n",
            "Epoch 44/500\n",
            "24/24 - 0s - loss: 0.4718 - accuracy: 0.7787 - 35ms/epoch - 1ms/step\n",
            "Epoch 45/500\n",
            "24/24 - 0s - loss: 0.4694 - accuracy: 0.7733 - 36ms/epoch - 2ms/step\n",
            "Epoch 46/500\n",
            "24/24 - 0s - loss: 0.4707 - accuracy: 0.7693 - 43ms/epoch - 2ms/step\n",
            "Epoch 47/500\n",
            "24/24 - 0s - loss: 0.4684 - accuracy: 0.7760 - 51ms/epoch - 2ms/step\n",
            "Epoch 48/500\n",
            "24/24 - 0s - loss: 0.4721 - accuracy: 0.7707 - 38ms/epoch - 2ms/step\n",
            "Epoch 49/500\n",
            "24/24 - 0s - loss: 0.4673 - accuracy: 0.7867 - 36ms/epoch - 1ms/step\n",
            "Epoch 50/500\n",
            "24/24 - 0s - loss: 0.4754 - accuracy: 0.7747 - 36ms/epoch - 2ms/step\n",
            "Epoch 51/500\n",
            "24/24 - 0s - loss: 0.4686 - accuracy: 0.7693 - 42ms/epoch - 2ms/step\n",
            "Epoch 52/500\n",
            "24/24 - 0s - loss: 0.4660 - accuracy: 0.7693 - 42ms/epoch - 2ms/step\n",
            "Epoch 53/500\n",
            "24/24 - 0s - loss: 0.4745 - accuracy: 0.7720 - 39ms/epoch - 2ms/step\n",
            "Epoch 54/500\n",
            "24/24 - 0s - loss: 0.4676 - accuracy: 0.7747 - 36ms/epoch - 2ms/step\n",
            "Epoch 55/500\n",
            "24/24 - 0s - loss: 0.4645 - accuracy: 0.7747 - 40ms/epoch - 2ms/step\n",
            "Epoch 56/500\n",
            "24/24 - 0s - loss: 0.4661 - accuracy: 0.7773 - 38ms/epoch - 2ms/step\n",
            "Epoch 57/500\n",
            "24/24 - 0s - loss: 0.4672 - accuracy: 0.7693 - 39ms/epoch - 2ms/step\n",
            "Epoch 58/500\n",
            "24/24 - 0s - loss: 0.4647 - accuracy: 0.7787 - 37ms/epoch - 2ms/step\n",
            "Epoch 59/500\n",
            "24/24 - 0s - loss: 0.4650 - accuracy: 0.7733 - 59ms/epoch - 2ms/step\n",
            "Epoch 60/500\n",
            "24/24 - 0s - loss: 0.4635 - accuracy: 0.7747 - 62ms/epoch - 3ms/step\n",
            "Epoch 61/500\n",
            "24/24 - 0s - loss: 0.4635 - accuracy: 0.7733 - 57ms/epoch - 2ms/step\n",
            "Epoch 62/500\n",
            "24/24 - 0s - loss: 0.4630 - accuracy: 0.7800 - 73ms/epoch - 3ms/step\n",
            "Epoch 63/500\n",
            "24/24 - 0s - loss: 0.4651 - accuracy: 0.7760 - 66ms/epoch - 3ms/step\n",
            "Epoch 64/500\n",
            "24/24 - 0s - loss: 0.4652 - accuracy: 0.7760 - 57ms/epoch - 2ms/step\n",
            "Epoch 65/500\n",
            "24/24 - 0s - loss: 0.4714 - accuracy: 0.7693 - 41ms/epoch - 2ms/step\n",
            "Epoch 66/500\n",
            "24/24 - 0s - loss: 0.4604 - accuracy: 0.7813 - 54ms/epoch - 2ms/step\n",
            "Epoch 67/500\n",
            "24/24 - 0s - loss: 0.4657 - accuracy: 0.7800 - 44ms/epoch - 2ms/step\n",
            "Epoch 68/500\n",
            "24/24 - 0s - loss: 0.4667 - accuracy: 0.7733 - 42ms/epoch - 2ms/step\n",
            "Epoch 69/500\n",
            "24/24 - 0s - loss: 0.4631 - accuracy: 0.7773 - 41ms/epoch - 2ms/step\n",
            "Epoch 70/500\n",
            "24/24 - 0s - loss: 0.4627 - accuracy: 0.7787 - 51ms/epoch - 2ms/step\n",
            "Epoch 71/500\n",
            "24/24 - 0s - loss: 0.4645 - accuracy: 0.7813 - 45ms/epoch - 2ms/step\n",
            "Epoch 72/500\n",
            "24/24 - 0s - loss: 0.4704 - accuracy: 0.7733 - 49ms/epoch - 2ms/step\n",
            "Epoch 73/500\n",
            "24/24 - 0s - loss: 0.4717 - accuracy: 0.7680 - 38ms/epoch - 2ms/step\n",
            "Epoch 74/500\n",
            "24/24 - 0s - loss: 0.4606 - accuracy: 0.7760 - 36ms/epoch - 1ms/step\n",
            "Epoch 75/500\n",
            "24/24 - 0s - loss: 0.4611 - accuracy: 0.7760 - 46ms/epoch - 2ms/step\n",
            "Epoch 76/500\n",
            "24/24 - 0s - loss: 0.4600 - accuracy: 0.7707 - 36ms/epoch - 1ms/step\n",
            "Epoch 77/500\n",
            "24/24 - 0s - loss: 0.4614 - accuracy: 0.7853 - 35ms/epoch - 1ms/step\n",
            "Epoch 78/500\n",
            "24/24 - 0s - loss: 0.4652 - accuracy: 0.7813 - 38ms/epoch - 2ms/step\n",
            "Epoch 79/500\n",
            "24/24 - 0s - loss: 0.4607 - accuracy: 0.7747 - 37ms/epoch - 2ms/step\n",
            "Epoch 80/500\n",
            "24/24 - 0s - loss: 0.4611 - accuracy: 0.7747 - 45ms/epoch - 2ms/step\n",
            "Epoch 81/500\n",
            "24/24 - 0s - loss: 0.4604 - accuracy: 0.7787 - 41ms/epoch - 2ms/step\n",
            "Epoch 82/500\n",
            "24/24 - 0s - loss: 0.4681 - accuracy: 0.7720 - 39ms/epoch - 2ms/step\n",
            "Epoch 83/500\n",
            "24/24 - 0s - loss: 0.4648 - accuracy: 0.7627 - 38ms/epoch - 2ms/step\n",
            "Epoch 84/500\n",
            "24/24 - 0s - loss: 0.4586 - accuracy: 0.7813 - 38ms/epoch - 2ms/step\n",
            "Epoch 85/500\n",
            "24/24 - 0s - loss: 0.4673 - accuracy: 0.7773 - 40ms/epoch - 2ms/step\n",
            "Epoch 86/500\n",
            "24/24 - 0s - loss: 0.4603 - accuracy: 0.7773 - 43ms/epoch - 2ms/step\n",
            "Epoch 87/500\n",
            "24/24 - 0s - loss: 0.4687 - accuracy: 0.7760 - 42ms/epoch - 2ms/step\n",
            "Epoch 88/500\n",
            "24/24 - 0s - loss: 0.4612 - accuracy: 0.7827 - 49ms/epoch - 2ms/step\n",
            "Epoch 89/500\n",
            "24/24 - 0s - loss: 0.4588 - accuracy: 0.7760 - 39ms/epoch - 2ms/step\n",
            "Epoch 90/500\n",
            "24/24 - 0s - loss: 0.4621 - accuracy: 0.7787 - 40ms/epoch - 2ms/step\n",
            "Epoch 91/500\n",
            "24/24 - 0s - loss: 0.4683 - accuracy: 0.7760 - 46ms/epoch - 2ms/step\n",
            "Epoch 92/500\n",
            "24/24 - 0s - loss: 0.4620 - accuracy: 0.7853 - 41ms/epoch - 2ms/step\n",
            "Epoch 93/500\n",
            "24/24 - 0s - loss: 0.4563 - accuracy: 0.7800 - 41ms/epoch - 2ms/step\n",
            "Epoch 94/500\n",
            "24/24 - 0s - loss: 0.4600 - accuracy: 0.7813 - 41ms/epoch - 2ms/step\n",
            "Epoch 95/500\n",
            "24/24 - 0s - loss: 0.4573 - accuracy: 0.7760 - 45ms/epoch - 2ms/step\n",
            "Epoch 96/500\n",
            "24/24 - 0s - loss: 0.4586 - accuracy: 0.7800 - 41ms/epoch - 2ms/step\n",
            "Epoch 97/500\n",
            "24/24 - 0s - loss: 0.4588 - accuracy: 0.7813 - 43ms/epoch - 2ms/step\n",
            "Epoch 98/500\n",
            "24/24 - 0s - loss: 0.4572 - accuracy: 0.7840 - 46ms/epoch - 2ms/step\n",
            "Epoch 99/500\n",
            "24/24 - 0s - loss: 0.4572 - accuracy: 0.7720 - 47ms/epoch - 2ms/step\n",
            "Epoch 100/500\n",
            "24/24 - 0s - loss: 0.4553 - accuracy: 0.7787 - 38ms/epoch - 2ms/step\n",
            "Epoch 101/500\n",
            "24/24 - 0s - loss: 0.4604 - accuracy: 0.7760 - 38ms/epoch - 2ms/step\n",
            "Epoch 102/500\n",
            "24/24 - 0s - loss: 0.4647 - accuracy: 0.7787 - 44ms/epoch - 2ms/step\n",
            "Epoch 103/500\n",
            "24/24 - 0s - loss: 0.4520 - accuracy: 0.7893 - 38ms/epoch - 2ms/step\n",
            "Epoch 104/500\n",
            "24/24 - 0s - loss: 0.4595 - accuracy: 0.7800 - 40ms/epoch - 2ms/step\n",
            "Epoch 105/500\n",
            "24/24 - 0s - loss: 0.4558 - accuracy: 0.7827 - 43ms/epoch - 2ms/step\n",
            "Epoch 106/500\n",
            "24/24 - 0s - loss: 0.4557 - accuracy: 0.7840 - 43ms/epoch - 2ms/step\n",
            "Epoch 107/500\n",
            "24/24 - 0s - loss: 0.4537 - accuracy: 0.7880 - 35ms/epoch - 1ms/step\n",
            "Epoch 108/500\n",
            "24/24 - 0s - loss: 0.4598 - accuracy: 0.7680 - 43ms/epoch - 2ms/step\n",
            "Epoch 109/500\n",
            "24/24 - 0s - loss: 0.4539 - accuracy: 0.7827 - 38ms/epoch - 2ms/step\n",
            "Epoch 110/500\n",
            "24/24 - 0s - loss: 0.4529 - accuracy: 0.7773 - 49ms/epoch - 2ms/step\n",
            "Epoch 111/500\n",
            "24/24 - 0s - loss: 0.4640 - accuracy: 0.7813 - 39ms/epoch - 2ms/step\n",
            "Epoch 112/500\n",
            "24/24 - 0s - loss: 0.4556 - accuracy: 0.7747 - 38ms/epoch - 2ms/step\n",
            "Epoch 113/500\n",
            "24/24 - 0s - loss: 0.4555 - accuracy: 0.7853 - 41ms/epoch - 2ms/step\n",
            "Epoch 114/500\n",
            "24/24 - 0s - loss: 0.4567 - accuracy: 0.7840 - 40ms/epoch - 2ms/step\n",
            "Epoch 115/500\n",
            "24/24 - 0s - loss: 0.4545 - accuracy: 0.7840 - 37ms/epoch - 2ms/step\n",
            "Epoch 116/500\n",
            "24/24 - 0s - loss: 0.4538 - accuracy: 0.7827 - 39ms/epoch - 2ms/step\n",
            "Epoch 117/500\n",
            "24/24 - 0s - loss: 0.4520 - accuracy: 0.7840 - 35ms/epoch - 1ms/step\n",
            "Epoch 118/500\n",
            "24/24 - 0s - loss: 0.4548 - accuracy: 0.7853 - 40ms/epoch - 2ms/step\n",
            "Epoch 119/500\n",
            "24/24 - 0s - loss: 0.4546 - accuracy: 0.7800 - 37ms/epoch - 2ms/step\n",
            "Epoch 120/500\n",
            "24/24 - 0s - loss: 0.4523 - accuracy: 0.7853 - 42ms/epoch - 2ms/step\n",
            "Epoch 121/500\n",
            "24/24 - 0s - loss: 0.4533 - accuracy: 0.7747 - 43ms/epoch - 2ms/step\n",
            "Epoch 122/500\n",
            "24/24 - 0s - loss: 0.4555 - accuracy: 0.7813 - 51ms/epoch - 2ms/step\n",
            "Epoch 123/500\n",
            "24/24 - 0s - loss: 0.4554 - accuracy: 0.7800 - 48ms/epoch - 2ms/step\n",
            "Epoch 124/500\n",
            "24/24 - 0s - loss: 0.4516 - accuracy: 0.7800 - 53ms/epoch - 2ms/step\n",
            "Epoch 125/500\n",
            "24/24 - 0s - loss: 0.4555 - accuracy: 0.7813 - 95ms/epoch - 4ms/step\n",
            "Epoch 126/500\n",
            "24/24 - 0s - loss: 0.4575 - accuracy: 0.7840 - 70ms/epoch - 3ms/step\n",
            "Epoch 127/500\n",
            "24/24 - 0s - loss: 0.4596 - accuracy: 0.7907 - 105ms/epoch - 4ms/step\n",
            "Epoch 128/500\n",
            "24/24 - 0s - loss: 0.4547 - accuracy: 0.7840 - 76ms/epoch - 3ms/step\n",
            "Epoch 129/500\n",
            "24/24 - 0s - loss: 0.4531 - accuracy: 0.7800 - 70ms/epoch - 3ms/step\n",
            "Epoch 130/500\n",
            "24/24 - 0s - loss: 0.4550 - accuracy: 0.7733 - 60ms/epoch - 3ms/step\n",
            "Epoch 131/500\n",
            "24/24 - 0s - loss: 0.4519 - accuracy: 0.7813 - 59ms/epoch - 2ms/step\n",
            "Epoch 132/500\n",
            "24/24 - 0s - loss: 0.4519 - accuracy: 0.7840 - 59ms/epoch - 2ms/step\n",
            "Epoch 133/500\n",
            "24/24 - 0s - loss: 0.4520 - accuracy: 0.7853 - 51ms/epoch - 2ms/step\n",
            "Epoch 134/500\n",
            "24/24 - 0s - loss: 0.4517 - accuracy: 0.7827 - 87ms/epoch - 4ms/step\n",
            "Epoch 135/500\n",
            "24/24 - 0s - loss: 0.4509 - accuracy: 0.7773 - 91ms/epoch - 4ms/step\n",
            "Epoch 136/500\n",
            "24/24 - 0s - loss: 0.4523 - accuracy: 0.7787 - 56ms/epoch - 2ms/step\n",
            "Epoch 137/500\n",
            "24/24 - 0s - loss: 0.4513 - accuracy: 0.7813 - 67ms/epoch - 3ms/step\n",
            "Epoch 138/500\n",
            "24/24 - 0s - loss: 0.4510 - accuracy: 0.7827 - 68ms/epoch - 3ms/step\n",
            "Epoch 139/500\n",
            "24/24 - 0s - loss: 0.4495 - accuracy: 0.7827 - 68ms/epoch - 3ms/step\n",
            "Epoch 140/500\n",
            "24/24 - 0s - loss: 0.4493 - accuracy: 0.7787 - 85ms/epoch - 4ms/step\n",
            "Epoch 141/500\n",
            "24/24 - 0s - loss: 0.4500 - accuracy: 0.7920 - 85ms/epoch - 4ms/step\n",
            "Epoch 142/500\n",
            "24/24 - 0s - loss: 0.4498 - accuracy: 0.7813 - 81ms/epoch - 3ms/step\n",
            "Epoch 143/500\n",
            "24/24 - 0s - loss: 0.4529 - accuracy: 0.7827 - 85ms/epoch - 4ms/step\n",
            "Epoch 144/500\n",
            "24/24 - 0s - loss: 0.4503 - accuracy: 0.7813 - 70ms/epoch - 3ms/step\n",
            "Epoch 145/500\n",
            "24/24 - 0s - loss: 0.4508 - accuracy: 0.7840 - 57ms/epoch - 2ms/step\n",
            "Epoch 146/500\n",
            "24/24 - 0s - loss: 0.4524 - accuracy: 0.7773 - 59ms/epoch - 2ms/step\n",
            "Epoch 147/500\n",
            "24/24 - 0s - loss: 0.4473 - accuracy: 0.7827 - 57ms/epoch - 2ms/step\n",
            "Epoch 148/500\n",
            "24/24 - 0s - loss: 0.4470 - accuracy: 0.7840 - 77ms/epoch - 3ms/step\n",
            "Epoch 149/500\n",
            "24/24 - 0s - loss: 0.4504 - accuracy: 0.7853 - 73ms/epoch - 3ms/step\n",
            "Epoch 150/500\n",
            "24/24 - 0s - loss: 0.4512 - accuracy: 0.7827 - 57ms/epoch - 2ms/step\n",
            "Epoch 151/500\n",
            "24/24 - 0s - loss: 0.4462 - accuracy: 0.7813 - 88ms/epoch - 4ms/step\n",
            "Epoch 152/500\n",
            "24/24 - 0s - loss: 0.4460 - accuracy: 0.7867 - 66ms/epoch - 3ms/step\n",
            "Epoch 153/500\n",
            "24/24 - 0s - loss: 0.4468 - accuracy: 0.7867 - 127ms/epoch - 5ms/step\n",
            "Epoch 154/500\n",
            "24/24 - 0s - loss: 0.4456 - accuracy: 0.7853 - 87ms/epoch - 4ms/step\n",
            "Epoch 155/500\n",
            "24/24 - 0s - loss: 0.4509 - accuracy: 0.7760 - 97ms/epoch - 4ms/step\n",
            "Epoch 156/500\n",
            "24/24 - 0s - loss: 0.4466 - accuracy: 0.7787 - 60ms/epoch - 3ms/step\n",
            "Epoch 157/500\n",
            "24/24 - 0s - loss: 0.4490 - accuracy: 0.7827 - 72ms/epoch - 3ms/step\n",
            "Epoch 158/500\n",
            "24/24 - 0s - loss: 0.4546 - accuracy: 0.7773 - 44ms/epoch - 2ms/step\n",
            "Epoch 159/500\n",
            "24/24 - 0s - loss: 0.4503 - accuracy: 0.7840 - 53ms/epoch - 2ms/step\n",
            "Epoch 160/500\n",
            "24/24 - 0s - loss: 0.4497 - accuracy: 0.7773 - 64ms/epoch - 3ms/step\n",
            "Epoch 161/500\n",
            "24/24 - 0s - loss: 0.4489 - accuracy: 0.7800 - 59ms/epoch - 2ms/step\n",
            "Epoch 162/500\n",
            "24/24 - 0s - loss: 0.4457 - accuracy: 0.7813 - 64ms/epoch - 3ms/step\n",
            "Epoch 163/500\n",
            "24/24 - 0s - loss: 0.4450 - accuracy: 0.7760 - 65ms/epoch - 3ms/step\n",
            "Epoch 164/500\n",
            "24/24 - 0s - loss: 0.4452 - accuracy: 0.7867 - 105ms/epoch - 4ms/step\n",
            "Epoch 165/500\n",
            "24/24 - 0s - loss: 0.4480 - accuracy: 0.7840 - 61ms/epoch - 3ms/step\n",
            "Epoch 166/500\n",
            "24/24 - 0s - loss: 0.4471 - accuracy: 0.7760 - 78ms/epoch - 3ms/step\n",
            "Epoch 167/500\n",
            "24/24 - 0s - loss: 0.4466 - accuracy: 0.7787 - 62ms/epoch - 3ms/step\n",
            "Epoch 168/500\n",
            "24/24 - 0s - loss: 0.4447 - accuracy: 0.7853 - 86ms/epoch - 4ms/step\n",
            "Epoch 169/500\n",
            "24/24 - 0s - loss: 0.4445 - accuracy: 0.7867 - 110ms/epoch - 5ms/step\n",
            "Epoch 170/500\n",
            "24/24 - 0s - loss: 0.4456 - accuracy: 0.7827 - 76ms/epoch - 3ms/step\n",
            "Epoch 171/500\n",
            "24/24 - 0s - loss: 0.4435 - accuracy: 0.7827 - 90ms/epoch - 4ms/step\n",
            "Epoch 172/500\n",
            "24/24 - 0s - loss: 0.4432 - accuracy: 0.7773 - 64ms/epoch - 3ms/step\n",
            "Epoch 173/500\n",
            "24/24 - 0s - loss: 0.4463 - accuracy: 0.7800 - 52ms/epoch - 2ms/step\n",
            "Epoch 174/500\n",
            "24/24 - 0s - loss: 0.4431 - accuracy: 0.7893 - 125ms/epoch - 5ms/step\n",
            "Epoch 175/500\n",
            "24/24 - 0s - loss: 0.4460 - accuracy: 0.7787 - 68ms/epoch - 3ms/step\n",
            "Epoch 176/500\n",
            "24/24 - 0s - loss: 0.4425 - accuracy: 0.7813 - 67ms/epoch - 3ms/step\n",
            "Epoch 177/500\n",
            "24/24 - 0s - loss: 0.4472 - accuracy: 0.7853 - 86ms/epoch - 4ms/step\n",
            "Epoch 178/500\n",
            "24/24 - 0s - loss: 0.4409 - accuracy: 0.7907 - 92ms/epoch - 4ms/step\n",
            "Epoch 179/500\n",
            "24/24 - 0s - loss: 0.4440 - accuracy: 0.7827 - 62ms/epoch - 3ms/step\n",
            "Epoch 180/500\n",
            "24/24 - 0s - loss: 0.4447 - accuracy: 0.7773 - 59ms/epoch - 2ms/step\n",
            "Epoch 181/500\n",
            "24/24 - 0s - loss: 0.4440 - accuracy: 0.7760 - 99ms/epoch - 4ms/step\n",
            "Epoch 182/500\n",
            "24/24 - 0s - loss: 0.4458 - accuracy: 0.7773 - 100ms/epoch - 4ms/step\n",
            "Epoch 183/500\n",
            "24/24 - 0s - loss: 0.4419 - accuracy: 0.7800 - 99ms/epoch - 4ms/step\n",
            "Epoch 184/500\n",
            "24/24 - 0s - loss: 0.4475 - accuracy: 0.7773 - 57ms/epoch - 2ms/step\n",
            "Epoch 185/500\n",
            "24/24 - 0s - loss: 0.4474 - accuracy: 0.7787 - 114ms/epoch - 5ms/step\n",
            "Epoch 186/500\n",
            "24/24 - 0s - loss: 0.4440 - accuracy: 0.7827 - 71ms/epoch - 3ms/step\n",
            "Epoch 187/500\n",
            "24/24 - 0s - loss: 0.4420 - accuracy: 0.7813 - 62ms/epoch - 3ms/step\n",
            "Epoch 188/500\n",
            "24/24 - 0s - loss: 0.4430 - accuracy: 0.7773 - 65ms/epoch - 3ms/step\n",
            "Epoch 189/500\n",
            "24/24 - 0s - loss: 0.4449 - accuracy: 0.7867 - 108ms/epoch - 4ms/step\n",
            "Epoch 190/500\n",
            "24/24 - 0s - loss: 0.4398 - accuracy: 0.7893 - 86ms/epoch - 4ms/step\n",
            "Epoch 191/500\n",
            "24/24 - 0s - loss: 0.4491 - accuracy: 0.7827 - 67ms/epoch - 3ms/step\n",
            "Epoch 192/500\n",
            "24/24 - 0s - loss: 0.4455 - accuracy: 0.7867 - 67ms/epoch - 3ms/step\n",
            "Epoch 193/500\n",
            "24/24 - 0s - loss: 0.4429 - accuracy: 0.7933 - 95ms/epoch - 4ms/step\n",
            "Epoch 194/500\n",
            "24/24 - 0s - loss: 0.4435 - accuracy: 0.7907 - 78ms/epoch - 3ms/step\n",
            "Epoch 195/500\n",
            "24/24 - 0s - loss: 0.4438 - accuracy: 0.7800 - 74ms/epoch - 3ms/step\n",
            "Epoch 196/500\n",
            "24/24 - 0s - loss: 0.4418 - accuracy: 0.7827 - 67ms/epoch - 3ms/step\n",
            "Epoch 197/500\n",
            "24/24 - 0s - loss: 0.4417 - accuracy: 0.7893 - 88ms/epoch - 4ms/step\n",
            "Epoch 198/500\n",
            "24/24 - 0s - loss: 0.4409 - accuracy: 0.7840 - 80ms/epoch - 3ms/step\n",
            "Epoch 199/500\n",
            "24/24 - 0s - loss: 0.4396 - accuracy: 0.7827 - 109ms/epoch - 5ms/step\n",
            "Epoch 200/500\n",
            "24/24 - 0s - loss: 0.4404 - accuracy: 0.7853 - 107ms/epoch - 4ms/step\n",
            "Epoch 201/500\n",
            "24/24 - 0s - loss: 0.4387 - accuracy: 0.7787 - 87ms/epoch - 4ms/step\n",
            "Epoch 202/500\n",
            "24/24 - 0s - loss: 0.4481 - accuracy: 0.7853 - 74ms/epoch - 3ms/step\n",
            "Epoch 203/500\n",
            "24/24 - 0s - loss: 0.4439 - accuracy: 0.7920 - 146ms/epoch - 6ms/step\n",
            "Epoch 204/500\n",
            "24/24 - 0s - loss: 0.4469 - accuracy: 0.7773 - 89ms/epoch - 4ms/step\n",
            "Epoch 205/500\n",
            "24/24 - 0s - loss: 0.4412 - accuracy: 0.7880 - 52ms/epoch - 2ms/step\n",
            "Epoch 206/500\n",
            "24/24 - 0s - loss: 0.4409 - accuracy: 0.7813 - 72ms/epoch - 3ms/step\n",
            "Epoch 207/500\n",
            "24/24 - 0s - loss: 0.4394 - accuracy: 0.7840 - 104ms/epoch - 4ms/step\n",
            "Epoch 208/500\n",
            "24/24 - 0s - loss: 0.4404 - accuracy: 0.7853 - 101ms/epoch - 4ms/step\n",
            "Epoch 209/500\n",
            "24/24 - 0s - loss: 0.4407 - accuracy: 0.7813 - 73ms/epoch - 3ms/step\n",
            "Epoch 210/500\n",
            "24/24 - 0s - loss: 0.4385 - accuracy: 0.7867 - 65ms/epoch - 3ms/step\n",
            "Epoch 211/500\n",
            "24/24 - 0s - loss: 0.4416 - accuracy: 0.7800 - 80ms/epoch - 3ms/step\n",
            "Epoch 212/500\n",
            "24/24 - 0s - loss: 0.4380 - accuracy: 0.7880 - 104ms/epoch - 4ms/step\n",
            "Epoch 213/500\n",
            "24/24 - 0s - loss: 0.4376 - accuracy: 0.7813 - 57ms/epoch - 2ms/step\n",
            "Epoch 214/500\n",
            "24/24 - 0s - loss: 0.4379 - accuracy: 0.7880 - 105ms/epoch - 4ms/step\n",
            "Epoch 215/500\n",
            "24/24 - 0s - loss: 0.4419 - accuracy: 0.7987 - 89ms/epoch - 4ms/step\n",
            "Epoch 216/500\n",
            "24/24 - 0s - loss: 0.4423 - accuracy: 0.7813 - 71ms/epoch - 3ms/step\n",
            "Epoch 217/500\n",
            "24/24 - 0s - loss: 0.4403 - accuracy: 0.7947 - 66ms/epoch - 3ms/step\n",
            "Epoch 218/500\n",
            "24/24 - 0s - loss: 0.4388 - accuracy: 0.7773 - 88ms/epoch - 4ms/step\n",
            "Epoch 219/500\n",
            "24/24 - 0s - loss: 0.4379 - accuracy: 0.7747 - 99ms/epoch - 4ms/step\n",
            "Epoch 220/500\n",
            "24/24 - 0s - loss: 0.4367 - accuracy: 0.7800 - 62ms/epoch - 3ms/step\n",
            "Epoch 221/500\n",
            "24/24 - 0s - loss: 0.4397 - accuracy: 0.7867 - 95ms/epoch - 4ms/step\n",
            "Epoch 222/500\n",
            "24/24 - 0s - loss: 0.4363 - accuracy: 0.7893 - 87ms/epoch - 4ms/step\n",
            "Epoch 223/500\n",
            "24/24 - 0s - loss: 0.4423 - accuracy: 0.7867 - 62ms/epoch - 3ms/step\n",
            "Epoch 224/500\n",
            "24/24 - 0s - loss: 0.4367 - accuracy: 0.7853 - 57ms/epoch - 2ms/step\n",
            "Epoch 225/500\n",
            "24/24 - 0s - loss: 0.4373 - accuracy: 0.7760 - 56ms/epoch - 2ms/step\n",
            "Epoch 226/500\n",
            "24/24 - 0s - loss: 0.4366 - accuracy: 0.7840 - 55ms/epoch - 2ms/step\n",
            "Epoch 227/500\n",
            "24/24 - 0s - loss: 0.4378 - accuracy: 0.7800 - 63ms/epoch - 3ms/step\n",
            "Epoch 228/500\n",
            "24/24 - 0s - loss: 0.4364 - accuracy: 0.7920 - 136ms/epoch - 6ms/step\n",
            "Epoch 229/500\n",
            "24/24 - 0s - loss: 0.4413 - accuracy: 0.7893 - 78ms/epoch - 3ms/step\n",
            "Epoch 230/500\n",
            "24/24 - 0s - loss: 0.4371 - accuracy: 0.7827 - 79ms/epoch - 3ms/step\n",
            "Epoch 231/500\n",
            "24/24 - 0s - loss: 0.4379 - accuracy: 0.7787 - 87ms/epoch - 4ms/step\n",
            "Epoch 232/500\n",
            "24/24 - 0s - loss: 0.4374 - accuracy: 0.7867 - 87ms/epoch - 4ms/step\n",
            "Epoch 233/500\n",
            "24/24 - 0s - loss: 0.4354 - accuracy: 0.7800 - 62ms/epoch - 3ms/step\n",
            "Epoch 234/500\n",
            "24/24 - 0s - loss: 0.4436 - accuracy: 0.7813 - 93ms/epoch - 4ms/step\n",
            "Epoch 235/500\n",
            "24/24 - 0s - loss: 0.4342 - accuracy: 0.7867 - 80ms/epoch - 3ms/step\n",
            "Epoch 236/500\n",
            "24/24 - 0s - loss: 0.4400 - accuracy: 0.7827 - 51ms/epoch - 2ms/step\n",
            "Epoch 237/500\n",
            "24/24 - 0s - loss: 0.4391 - accuracy: 0.7827 - 62ms/epoch - 3ms/step\n",
            "Epoch 238/500\n",
            "24/24 - 0s - loss: 0.4391 - accuracy: 0.7693 - 89ms/epoch - 4ms/step\n",
            "Epoch 239/500\n",
            "24/24 - 0s - loss: 0.4380 - accuracy: 0.7760 - 72ms/epoch - 3ms/step\n",
            "Epoch 240/500\n",
            "24/24 - 0s - loss: 0.4347 - accuracy: 0.7813 - 55ms/epoch - 2ms/step\n",
            "Epoch 241/500\n",
            "24/24 - 0s - loss: 0.4353 - accuracy: 0.7787 - 64ms/epoch - 3ms/step\n",
            "Epoch 242/500\n",
            "24/24 - 0s - loss: 0.4332 - accuracy: 0.7853 - 70ms/epoch - 3ms/step\n",
            "Epoch 243/500\n",
            "24/24 - 0s - loss: 0.4386 - accuracy: 0.7987 - 75ms/epoch - 3ms/step\n",
            "Epoch 244/500\n",
            "24/24 - 0s - loss: 0.4353 - accuracy: 0.7893 - 71ms/epoch - 3ms/step\n",
            "Epoch 245/500\n",
            "24/24 - 0s - loss: 0.4392 - accuracy: 0.7867 - 58ms/epoch - 2ms/step\n",
            "Epoch 246/500\n",
            "24/24 - 0s - loss: 0.4362 - accuracy: 0.7933 - 79ms/epoch - 3ms/step\n",
            "Epoch 247/500\n",
            "24/24 - 0s - loss: 0.4358 - accuracy: 0.7880 - 144ms/epoch - 6ms/step\n",
            "Epoch 248/500\n",
            "24/24 - 0s - loss: 0.4361 - accuracy: 0.7773 - 82ms/epoch - 3ms/step\n",
            "Epoch 249/500\n",
            "24/24 - 0s - loss: 0.4358 - accuracy: 0.7827 - 56ms/epoch - 2ms/step\n",
            "Epoch 250/500\n",
            "24/24 - 0s - loss: 0.4363 - accuracy: 0.7787 - 53ms/epoch - 2ms/step\n",
            "Epoch 251/500\n",
            "24/24 - 0s - loss: 0.4354 - accuracy: 0.7880 - 63ms/epoch - 3ms/step\n",
            "Epoch 252/500\n",
            "24/24 - 0s - loss: 0.4426 - accuracy: 0.7827 - 73ms/epoch - 3ms/step\n",
            "Epoch 253/500\n",
            "24/24 - 0s - loss: 0.4359 - accuracy: 0.7800 - 75ms/epoch - 3ms/step\n",
            "Epoch 254/500\n",
            "24/24 - 0s - loss: 0.4374 - accuracy: 0.7720 - 92ms/epoch - 4ms/step\n",
            "Epoch 255/500\n",
            "24/24 - 0s - loss: 0.4320 - accuracy: 0.7853 - 66ms/epoch - 3ms/step\n",
            "Epoch 256/500\n",
            "24/24 - 0s - loss: 0.4340 - accuracy: 0.7853 - 67ms/epoch - 3ms/step\n",
            "Epoch 257/500\n",
            "24/24 - 0s - loss: 0.4321 - accuracy: 0.7893 - 91ms/epoch - 4ms/step\n",
            "Epoch 258/500\n",
            "24/24 - 0s - loss: 0.4328 - accuracy: 0.7893 - 135ms/epoch - 6ms/step\n",
            "Epoch 259/500\n",
            "24/24 - 0s - loss: 0.4324 - accuracy: 0.7867 - 114ms/epoch - 5ms/step\n",
            "Epoch 260/500\n",
            "24/24 - 0s - loss: 0.4353 - accuracy: 0.7813 - 111ms/epoch - 5ms/step\n",
            "Epoch 261/500\n",
            "24/24 - 0s - loss: 0.4366 - accuracy: 0.7880 - 62ms/epoch - 3ms/step\n",
            "Epoch 262/500\n",
            "24/24 - 0s - loss: 0.4353 - accuracy: 0.7813 - 65ms/epoch - 3ms/step\n",
            "Epoch 263/500\n",
            "24/24 - 0s - loss: 0.4324 - accuracy: 0.7773 - 76ms/epoch - 3ms/step\n",
            "Epoch 264/500\n",
            "24/24 - 0s - loss: 0.4329 - accuracy: 0.7880 - 65ms/epoch - 3ms/step\n",
            "Epoch 265/500\n",
            "24/24 - 0s - loss: 0.4337 - accuracy: 0.7920 - 75ms/epoch - 3ms/step\n",
            "Epoch 266/500\n",
            "24/24 - 0s - loss: 0.4319 - accuracy: 0.7920 - 98ms/epoch - 4ms/step\n",
            "Epoch 267/500\n",
            "24/24 - 0s - loss: 0.4322 - accuracy: 0.7853 - 78ms/epoch - 3ms/step\n",
            "Epoch 268/500\n",
            "24/24 - 0s - loss: 0.4332 - accuracy: 0.7853 - 64ms/epoch - 3ms/step\n",
            "Epoch 269/500\n",
            "24/24 - 0s - loss: 0.4322 - accuracy: 0.7880 - 118ms/epoch - 5ms/step\n",
            "Epoch 270/500\n",
            "24/24 - 0s - loss: 0.4347 - accuracy: 0.7920 - 65ms/epoch - 3ms/step\n",
            "Epoch 271/500\n",
            "24/24 - 0s - loss: 0.4326 - accuracy: 0.7907 - 74ms/epoch - 3ms/step\n",
            "Epoch 272/500\n",
            "24/24 - 0s - loss: 0.4348 - accuracy: 0.7960 - 79ms/epoch - 3ms/step\n",
            "Epoch 273/500\n",
            "24/24 - 0s - loss: 0.4326 - accuracy: 0.7893 - 79ms/epoch - 3ms/step\n",
            "Epoch 274/500\n",
            "24/24 - 0s - loss: 0.4287 - accuracy: 0.7880 - 117ms/epoch - 5ms/step\n",
            "Epoch 275/500\n",
            "24/24 - 0s - loss: 0.4348 - accuracy: 0.7893 - 68ms/epoch - 3ms/step\n",
            "Epoch 276/500\n",
            "24/24 - 0s - loss: 0.4325 - accuracy: 0.7880 - 97ms/epoch - 4ms/step\n",
            "Epoch 277/500\n",
            "24/24 - 0s - loss: 0.4348 - accuracy: 0.7827 - 51ms/epoch - 2ms/step\n",
            "Epoch 278/500\n",
            "24/24 - 0s - loss: 0.4314 - accuracy: 0.7800 - 96ms/epoch - 4ms/step\n",
            "Epoch 279/500\n",
            "24/24 - 0s - loss: 0.4344 - accuracy: 0.7973 - 83ms/epoch - 3ms/step\n",
            "Epoch 280/500\n",
            "24/24 - 0s - loss: 0.4325 - accuracy: 0.7840 - 84ms/epoch - 4ms/step\n",
            "Epoch 281/500\n",
            "24/24 - 0s - loss: 0.4431 - accuracy: 0.7893 - 54ms/epoch - 2ms/step\n",
            "Epoch 282/500\n",
            "24/24 - 0s - loss: 0.4303 - accuracy: 0.7893 - 112ms/epoch - 5ms/step\n",
            "Epoch 283/500\n",
            "24/24 - 0s - loss: 0.4307 - accuracy: 0.7880 - 92ms/epoch - 4ms/step\n",
            "Epoch 284/500\n",
            "24/24 - 0s - loss: 0.4285 - accuracy: 0.7840 - 58ms/epoch - 2ms/step\n",
            "Epoch 285/500\n",
            "24/24 - 0s - loss: 0.4302 - accuracy: 0.7840 - 151ms/epoch - 6ms/step\n",
            "Epoch 286/500\n",
            "24/24 - 0s - loss: 0.4303 - accuracy: 0.7880 - 125ms/epoch - 5ms/step\n",
            "Epoch 287/500\n",
            "24/24 - 0s - loss: 0.4311 - accuracy: 0.7933 - 92ms/epoch - 4ms/step\n",
            "Epoch 288/500\n",
            "24/24 - 0s - loss: 0.4308 - accuracy: 0.7853 - 94ms/epoch - 4ms/step\n",
            "Epoch 289/500\n",
            "24/24 - 0s - loss: 0.4311 - accuracy: 0.8000 - 124ms/epoch - 5ms/step\n",
            "Epoch 290/500\n",
            "24/24 - 0s - loss: 0.4288 - accuracy: 0.7960 - 174ms/epoch - 7ms/step\n",
            "Epoch 291/500\n",
            "24/24 - 0s - loss: 0.4350 - accuracy: 0.7933 - 107ms/epoch - 4ms/step\n",
            "Epoch 292/500\n",
            "24/24 - 0s - loss: 0.4285 - accuracy: 0.7853 - 111ms/epoch - 5ms/step\n",
            "Epoch 293/500\n",
            "24/24 - 0s - loss: 0.4282 - accuracy: 0.7880 - 100ms/epoch - 4ms/step\n",
            "Epoch 294/500\n",
            "24/24 - 0s - loss: 0.4282 - accuracy: 0.7880 - 55ms/epoch - 2ms/step\n",
            "Epoch 295/500\n",
            "24/24 - 0s - loss: 0.4306 - accuracy: 0.7867 - 108ms/epoch - 5ms/step\n",
            "Epoch 296/500\n",
            "24/24 - 0s - loss: 0.4340 - accuracy: 0.7853 - 77ms/epoch - 3ms/step\n",
            "Epoch 297/500\n",
            "24/24 - 0s - loss: 0.4297 - accuracy: 0.7933 - 105ms/epoch - 4ms/step\n",
            "Epoch 298/500\n",
            "24/24 - 0s - loss: 0.4282 - accuracy: 0.7907 - 61ms/epoch - 3ms/step\n",
            "Epoch 299/500\n",
            "24/24 - 0s - loss: 0.4335 - accuracy: 0.8053 - 84ms/epoch - 3ms/step\n",
            "Epoch 300/500\n",
            "24/24 - 0s - loss: 0.4279 - accuracy: 0.7840 - 113ms/epoch - 5ms/step\n",
            "Epoch 301/500\n",
            "24/24 - 0s - loss: 0.4304 - accuracy: 0.7880 - 92ms/epoch - 4ms/step\n",
            "Epoch 302/500\n",
            "24/24 - 0s - loss: 0.4325 - accuracy: 0.7853 - 70ms/epoch - 3ms/step\n",
            "Epoch 303/500\n",
            "24/24 - 0s - loss: 0.4285 - accuracy: 0.7933 - 60ms/epoch - 3ms/step\n",
            "Epoch 304/500\n",
            "24/24 - 0s - loss: 0.4302 - accuracy: 0.7827 - 64ms/epoch - 3ms/step\n",
            "Epoch 305/500\n",
            "24/24 - 0s - loss: 0.4278 - accuracy: 0.7880 - 66ms/epoch - 3ms/step\n",
            "Epoch 306/500\n",
            "24/24 - 0s - loss: 0.4333 - accuracy: 0.7907 - 78ms/epoch - 3ms/step\n",
            "Epoch 307/500\n",
            "24/24 - 0s - loss: 0.4293 - accuracy: 0.7880 - 64ms/epoch - 3ms/step\n",
            "Epoch 308/500\n",
            "24/24 - 0s - loss: 0.4274 - accuracy: 0.7973 - 59ms/epoch - 2ms/step\n",
            "Epoch 309/500\n",
            "24/24 - 0s - loss: 0.4296 - accuracy: 0.7960 - 59ms/epoch - 2ms/step\n",
            "Epoch 310/500\n",
            "24/24 - 0s - loss: 0.4286 - accuracy: 0.7920 - 62ms/epoch - 3ms/step\n",
            "Epoch 311/500\n",
            "24/24 - 0s - loss: 0.4299 - accuracy: 0.7973 - 62ms/epoch - 3ms/step\n",
            "Epoch 312/500\n",
            "24/24 - 0s - loss: 0.4303 - accuracy: 0.7907 - 81ms/epoch - 3ms/step\n",
            "Epoch 313/500\n",
            "24/24 - 0s - loss: 0.4297 - accuracy: 0.7893 - 76ms/epoch - 3ms/step\n",
            "Epoch 314/500\n",
            "24/24 - 0s - loss: 0.4275 - accuracy: 0.7920 - 50ms/epoch - 2ms/step\n",
            "Epoch 315/500\n",
            "24/24 - 0s - loss: 0.4291 - accuracy: 0.7907 - 109ms/epoch - 5ms/step\n",
            "Epoch 316/500\n",
            "24/24 - 0s - loss: 0.4278 - accuracy: 0.7920 - 141ms/epoch - 6ms/step\n",
            "Epoch 317/500\n",
            "24/24 - 0s - loss: 0.4262 - accuracy: 0.7933 - 91ms/epoch - 4ms/step\n",
            "Epoch 318/500\n",
            "24/24 - 0s - loss: 0.4284 - accuracy: 0.7813 - 113ms/epoch - 5ms/step\n",
            "Epoch 319/500\n",
            "24/24 - 0s - loss: 0.4272 - accuracy: 0.7933 - 86ms/epoch - 4ms/step\n",
            "Epoch 320/500\n",
            "24/24 - 0s - loss: 0.4304 - accuracy: 0.7907 - 76ms/epoch - 3ms/step\n",
            "Epoch 321/500\n",
            "24/24 - 0s - loss: 0.4250 - accuracy: 0.7893 - 66ms/epoch - 3ms/step\n",
            "Epoch 322/500\n",
            "24/24 - 0s - loss: 0.4251 - accuracy: 0.7987 - 64ms/epoch - 3ms/step\n",
            "Epoch 323/500\n",
            "24/24 - 0s - loss: 0.4290 - accuracy: 0.7907 - 93ms/epoch - 4ms/step\n",
            "Epoch 324/500\n",
            "24/24 - 0s - loss: 0.4303 - accuracy: 0.7867 - 98ms/epoch - 4ms/step\n",
            "Epoch 325/500\n",
            "24/24 - 0s - loss: 0.4336 - accuracy: 0.7853 - 115ms/epoch - 5ms/step\n",
            "Epoch 326/500\n",
            "24/24 - 0s - loss: 0.4270 - accuracy: 0.7880 - 163ms/epoch - 7ms/step\n",
            "Epoch 327/500\n",
            "24/24 - 0s - loss: 0.4247 - accuracy: 0.7920 - 145ms/epoch - 6ms/step\n",
            "Epoch 328/500\n",
            "24/24 - 0s - loss: 0.4260 - accuracy: 0.8000 - 54ms/epoch - 2ms/step\n",
            "Epoch 329/500\n",
            "24/24 - 0s - loss: 0.4241 - accuracy: 0.7920 - 58ms/epoch - 2ms/step\n",
            "Epoch 330/500\n",
            "24/24 - 0s - loss: 0.4281 - accuracy: 0.7960 - 52ms/epoch - 2ms/step\n",
            "Epoch 331/500\n",
            "24/24 - 0s - loss: 0.4247 - accuracy: 0.7987 - 54ms/epoch - 2ms/step\n",
            "Epoch 332/500\n",
            "24/24 - 0s - loss: 0.4248 - accuracy: 0.7893 - 67ms/epoch - 3ms/step\n",
            "Epoch 333/500\n",
            "24/24 - 0s - loss: 0.4251 - accuracy: 0.7933 - 105ms/epoch - 4ms/step\n",
            "Epoch 334/500\n",
            "24/24 - 0s - loss: 0.4334 - accuracy: 0.7920 - 104ms/epoch - 4ms/step\n",
            "Epoch 335/500\n",
            "24/24 - 0s - loss: 0.4340 - accuracy: 0.7813 - 94ms/epoch - 4ms/step\n",
            "Epoch 336/500\n",
            "24/24 - 0s - loss: 0.4358 - accuracy: 0.7920 - 111ms/epoch - 5ms/step\n",
            "Epoch 337/500\n",
            "24/24 - 0s - loss: 0.4319 - accuracy: 0.7933 - 132ms/epoch - 5ms/step\n",
            "Epoch 338/500\n",
            "24/24 - 0s - loss: 0.4346 - accuracy: 0.7907 - 60ms/epoch - 3ms/step\n",
            "Epoch 339/500\n",
            "24/24 - 0s - loss: 0.4278 - accuracy: 0.7920 - 47ms/epoch - 2ms/step\n",
            "Epoch 340/500\n",
            "24/24 - 0s - loss: 0.4255 - accuracy: 0.7973 - 52ms/epoch - 2ms/step\n",
            "Epoch 341/500\n",
            "24/24 - 0s - loss: 0.4245 - accuracy: 0.7880 - 81ms/epoch - 3ms/step\n",
            "Epoch 342/500\n",
            "24/24 - 0s - loss: 0.4252 - accuracy: 0.7840 - 77ms/epoch - 3ms/step\n",
            "Epoch 343/500\n",
            "24/24 - 0s - loss: 0.4308 - accuracy: 0.7827 - 62ms/epoch - 3ms/step\n",
            "Epoch 344/500\n",
            "24/24 - 0s - loss: 0.4265 - accuracy: 0.8000 - 83ms/epoch - 3ms/step\n",
            "Epoch 345/500\n",
            "24/24 - 0s - loss: 0.4308 - accuracy: 0.7960 - 59ms/epoch - 2ms/step\n",
            "Epoch 346/500\n",
            "24/24 - 0s - loss: 0.4298 - accuracy: 0.7813 - 67ms/epoch - 3ms/step\n",
            "Epoch 347/500\n",
            "24/24 - 0s - loss: 0.4241 - accuracy: 0.8000 - 60ms/epoch - 2ms/step\n",
            "Epoch 348/500\n",
            "24/24 - 0s - loss: 0.4285 - accuracy: 0.7827 - 55ms/epoch - 2ms/step\n",
            "Epoch 349/500\n",
            "24/24 - 0s - loss: 0.4227 - accuracy: 0.7973 - 68ms/epoch - 3ms/step\n",
            "Epoch 350/500\n",
            "24/24 - 0s - loss: 0.4231 - accuracy: 0.7947 - 64ms/epoch - 3ms/step\n",
            "Epoch 351/500\n",
            "24/24 - 0s - loss: 0.4223 - accuracy: 0.7947 - 84ms/epoch - 4ms/step\n",
            "Epoch 352/500\n",
            "24/24 - 0s - loss: 0.4266 - accuracy: 0.7947 - 49ms/epoch - 2ms/step\n",
            "Epoch 353/500\n",
            "24/24 - 0s - loss: 0.4259 - accuracy: 0.7947 - 86ms/epoch - 4ms/step\n",
            "Epoch 354/500\n",
            "24/24 - 0s - loss: 0.4241 - accuracy: 0.8000 - 65ms/epoch - 3ms/step\n",
            "Epoch 355/500\n",
            "24/24 - 0s - loss: 0.4237 - accuracy: 0.7947 - 71ms/epoch - 3ms/step\n",
            "Epoch 356/500\n",
            "24/24 - 0s - loss: 0.4224 - accuracy: 0.7973 - 73ms/epoch - 3ms/step\n",
            "Epoch 357/500\n",
            "24/24 - 0s - loss: 0.4238 - accuracy: 0.7987 - 63ms/epoch - 3ms/step\n",
            "Epoch 358/500\n",
            "24/24 - 0s - loss: 0.4242 - accuracy: 0.8053 - 97ms/epoch - 4ms/step\n",
            "Epoch 359/500\n",
            "24/24 - 0s - loss: 0.4224 - accuracy: 0.8000 - 68ms/epoch - 3ms/step\n",
            "Epoch 360/500\n",
            "24/24 - 0s - loss: 0.4263 - accuracy: 0.7880 - 54ms/epoch - 2ms/step\n",
            "Epoch 361/500\n",
            "24/24 - 0s - loss: 0.4235 - accuracy: 0.7987 - 54ms/epoch - 2ms/step\n",
            "Epoch 362/500\n",
            "24/24 - 0s - loss: 0.4277 - accuracy: 0.7920 - 87ms/epoch - 4ms/step\n",
            "Epoch 363/500\n",
            "24/24 - 0s - loss: 0.4230 - accuracy: 0.7987 - 57ms/epoch - 2ms/step\n",
            "Epoch 364/500\n",
            "24/24 - 0s - loss: 0.4229 - accuracy: 0.8000 - 69ms/epoch - 3ms/step\n",
            "Epoch 365/500\n",
            "24/24 - 0s - loss: 0.4236 - accuracy: 0.7973 - 82ms/epoch - 3ms/step\n",
            "Epoch 366/500\n",
            "24/24 - 0s - loss: 0.4250 - accuracy: 0.7933 - 89ms/epoch - 4ms/step\n",
            "Epoch 367/500\n",
            "24/24 - 0s - loss: 0.4216 - accuracy: 0.7960 - 91ms/epoch - 4ms/step\n",
            "Epoch 368/500\n",
            "24/24 - 0s - loss: 0.4210 - accuracy: 0.8000 - 101ms/epoch - 4ms/step\n",
            "Epoch 369/500\n",
            "24/24 - 0s - loss: 0.4227 - accuracy: 0.8000 - 128ms/epoch - 5ms/step\n",
            "Epoch 370/500\n",
            "24/24 - 0s - loss: 0.4292 - accuracy: 0.8053 - 98ms/epoch - 4ms/step\n",
            "Epoch 371/500\n",
            "24/24 - 0s - loss: 0.4218 - accuracy: 0.7987 - 101ms/epoch - 4ms/step\n",
            "Epoch 372/500\n",
            "24/24 - 0s - loss: 0.4328 - accuracy: 0.8013 - 79ms/epoch - 3ms/step\n",
            "Epoch 373/500\n",
            "24/24 - 0s - loss: 0.4229 - accuracy: 0.7853 - 72ms/epoch - 3ms/step\n",
            "Epoch 374/500\n",
            "24/24 - 0s - loss: 0.4250 - accuracy: 0.7947 - 112ms/epoch - 5ms/step\n",
            "Epoch 375/500\n",
            "24/24 - 0s - loss: 0.4223 - accuracy: 0.7960 - 65ms/epoch - 3ms/step\n",
            "Epoch 376/500\n",
            "24/24 - 0s - loss: 0.4300 - accuracy: 0.7867 - 68ms/epoch - 3ms/step\n",
            "Epoch 377/500\n",
            "24/24 - 0s - loss: 0.4267 - accuracy: 0.7853 - 74ms/epoch - 3ms/step\n",
            "Epoch 378/500\n",
            "24/24 - 0s - loss: 0.4246 - accuracy: 0.8000 - 86ms/epoch - 4ms/step\n",
            "Epoch 379/500\n",
            "24/24 - 0s - loss: 0.4233 - accuracy: 0.7960 - 89ms/epoch - 4ms/step\n",
            "Epoch 380/500\n",
            "24/24 - 0s - loss: 0.4232 - accuracy: 0.8027 - 163ms/epoch - 7ms/step\n",
            "Epoch 381/500\n",
            "24/24 - 0s - loss: 0.4242 - accuracy: 0.7973 - 105ms/epoch - 4ms/step\n",
            "Epoch 382/500\n",
            "24/24 - 0s - loss: 0.4247 - accuracy: 0.7920 - 66ms/epoch - 3ms/step\n",
            "Epoch 383/500\n",
            "24/24 - 0s - loss: 0.4218 - accuracy: 0.7987 - 80ms/epoch - 3ms/step\n",
            "Epoch 384/500\n",
            "24/24 - 0s - loss: 0.4313 - accuracy: 0.7813 - 80ms/epoch - 3ms/step\n",
            "Epoch 385/500\n",
            "24/24 - 0s - loss: 0.4241 - accuracy: 0.7960 - 81ms/epoch - 3ms/step\n",
            "Epoch 386/500\n",
            "24/24 - 0s - loss: 0.4244 - accuracy: 0.7920 - 91ms/epoch - 4ms/step\n",
            "Epoch 387/500\n",
            "24/24 - 0s - loss: 0.4219 - accuracy: 0.8000 - 129ms/epoch - 5ms/step\n",
            "Epoch 388/500\n",
            "24/24 - 0s - loss: 0.4205 - accuracy: 0.8000 - 59ms/epoch - 2ms/step\n",
            "Epoch 389/500\n",
            "24/24 - 0s - loss: 0.4224 - accuracy: 0.7960 - 49ms/epoch - 2ms/step\n",
            "Epoch 390/500\n",
            "24/24 - 0s - loss: 0.4241 - accuracy: 0.8013 - 131ms/epoch - 5ms/step\n",
            "Epoch 391/500\n",
            "24/24 - 0s - loss: 0.4242 - accuracy: 0.7987 - 101ms/epoch - 4ms/step\n",
            "Epoch 392/500\n",
            "24/24 - 0s - loss: 0.4251 - accuracy: 0.7947 - 146ms/epoch - 6ms/step\n",
            "Epoch 393/500\n",
            "24/24 - 0s - loss: 0.4220 - accuracy: 0.7987 - 155ms/epoch - 6ms/step\n",
            "Epoch 394/500\n",
            "24/24 - 0s - loss: 0.4219 - accuracy: 0.7973 - 126ms/epoch - 5ms/step\n",
            "Epoch 395/500\n",
            "24/24 - 0s - loss: 0.4191 - accuracy: 0.8000 - 96ms/epoch - 4ms/step\n",
            "Epoch 396/500\n",
            "24/24 - 0s - loss: 0.4247 - accuracy: 0.7987 - 123ms/epoch - 5ms/step\n",
            "Epoch 397/500\n",
            "24/24 - 0s - loss: 0.4229 - accuracy: 0.7907 - 74ms/epoch - 3ms/step\n",
            "Epoch 398/500\n",
            "24/24 - 0s - loss: 0.4226 - accuracy: 0.7973 - 89ms/epoch - 4ms/step\n",
            "Epoch 399/500\n",
            "24/24 - 0s - loss: 0.4264 - accuracy: 0.7960 - 78ms/epoch - 3ms/step\n",
            "Epoch 400/500\n",
            "24/24 - 0s - loss: 0.4216 - accuracy: 0.7987 - 94ms/epoch - 4ms/step\n",
            "Epoch 401/500\n",
            "24/24 - 0s - loss: 0.4213 - accuracy: 0.7973 - 91ms/epoch - 4ms/step\n",
            "Epoch 402/500\n",
            "24/24 - 0s - loss: 0.4186 - accuracy: 0.7987 - 78ms/epoch - 3ms/step\n",
            "Epoch 403/500\n",
            "24/24 - 0s - loss: 0.4194 - accuracy: 0.8027 - 55ms/epoch - 2ms/step\n",
            "Epoch 404/500\n",
            "24/24 - 0s - loss: 0.4222 - accuracy: 0.8040 - 54ms/epoch - 2ms/step\n",
            "Epoch 405/500\n",
            "24/24 - 0s - loss: 0.4207 - accuracy: 0.7987 - 118ms/epoch - 5ms/step\n",
            "Epoch 406/500\n",
            "24/24 - 0s - loss: 0.4218 - accuracy: 0.8040 - 96ms/epoch - 4ms/step\n",
            "Epoch 407/500\n",
            "24/24 - 0s - loss: 0.4213 - accuracy: 0.7947 - 122ms/epoch - 5ms/step\n",
            "Epoch 408/500\n",
            "24/24 - 0s - loss: 0.4193 - accuracy: 0.8013 - 111ms/epoch - 5ms/step\n",
            "Epoch 409/500\n",
            "24/24 - 0s - loss: 0.4238 - accuracy: 0.8000 - 120ms/epoch - 5ms/step\n",
            "Epoch 410/500\n",
            "24/24 - 0s - loss: 0.4224 - accuracy: 0.7973 - 76ms/epoch - 3ms/step\n",
            "Epoch 411/500\n",
            "24/24 - 0s - loss: 0.4225 - accuracy: 0.7987 - 67ms/epoch - 3ms/step\n",
            "Epoch 412/500\n",
            "24/24 - 0s - loss: 0.4199 - accuracy: 0.8053 - 71ms/epoch - 3ms/step\n",
            "Epoch 413/500\n",
            "24/24 - 0s - loss: 0.4186 - accuracy: 0.8040 - 79ms/epoch - 3ms/step\n",
            "Epoch 414/500\n",
            "24/24 - 0s - loss: 0.4282 - accuracy: 0.8000 - 65ms/epoch - 3ms/step\n",
            "Epoch 415/500\n",
            "24/24 - 0s - loss: 0.4204 - accuracy: 0.8053 - 91ms/epoch - 4ms/step\n",
            "Epoch 416/500\n",
            "24/24 - 0s - loss: 0.4201 - accuracy: 0.7973 - 95ms/epoch - 4ms/step\n",
            "Epoch 417/500\n",
            "24/24 - 0s - loss: 0.4210 - accuracy: 0.8053 - 88ms/epoch - 4ms/step\n",
            "Epoch 418/500\n",
            "24/24 - 0s - loss: 0.4274 - accuracy: 0.7947 - 93ms/epoch - 4ms/step\n",
            "Epoch 419/500\n",
            "24/24 - 0s - loss: 0.4264 - accuracy: 0.7973 - 121ms/epoch - 5ms/step\n",
            "Epoch 420/500\n",
            "24/24 - 0s - loss: 0.4267 - accuracy: 0.7920 - 111ms/epoch - 5ms/step\n",
            "Epoch 421/500\n",
            "24/24 - 0s - loss: 0.4202 - accuracy: 0.8040 - 123ms/epoch - 5ms/step\n",
            "Epoch 422/500\n",
            "24/24 - 0s - loss: 0.4242 - accuracy: 0.8013 - 64ms/epoch - 3ms/step\n",
            "Epoch 423/500\n",
            "24/24 - 0s - loss: 0.4186 - accuracy: 0.8027 - 105ms/epoch - 4ms/step\n",
            "Epoch 424/500\n",
            "24/24 - 0s - loss: 0.4215 - accuracy: 0.8040 - 71ms/epoch - 3ms/step\n",
            "Epoch 425/500\n",
            "24/24 - 0s - loss: 0.4229 - accuracy: 0.8013 - 59ms/epoch - 2ms/step\n",
            "Epoch 426/500\n",
            "24/24 - 0s - loss: 0.4275 - accuracy: 0.7920 - 65ms/epoch - 3ms/step\n",
            "Epoch 427/500\n",
            "24/24 - 0s - loss: 0.4206 - accuracy: 0.8040 - 71ms/epoch - 3ms/step\n",
            "Epoch 428/500\n",
            "24/24 - 0s - loss: 0.4211 - accuracy: 0.8053 - 59ms/epoch - 2ms/step\n",
            "Epoch 429/500\n",
            "24/24 - 0s - loss: 0.4256 - accuracy: 0.7827 - 57ms/epoch - 2ms/step\n",
            "Epoch 430/500\n",
            "24/24 - 0s - loss: 0.4217 - accuracy: 0.7933 - 102ms/epoch - 4ms/step\n",
            "Epoch 431/500\n",
            "24/24 - 0s - loss: 0.4200 - accuracy: 0.8093 - 79ms/epoch - 3ms/step\n",
            "Epoch 432/500\n",
            "24/24 - 0s - loss: 0.4213 - accuracy: 0.7907 - 63ms/epoch - 3ms/step\n",
            "Epoch 433/500\n",
            "24/24 - 0s - loss: 0.4210 - accuracy: 0.7960 - 54ms/epoch - 2ms/step\n",
            "Epoch 434/500\n",
            "24/24 - 0s - loss: 0.4223 - accuracy: 0.7960 - 62ms/epoch - 3ms/step\n",
            "Epoch 435/500\n",
            "24/24 - 0s - loss: 0.4180 - accuracy: 0.8040 - 63ms/epoch - 3ms/step\n",
            "Epoch 436/500\n",
            "24/24 - 0s - loss: 0.4214 - accuracy: 0.8053 - 48ms/epoch - 2ms/step\n",
            "Epoch 437/500\n",
            "24/24 - 0s - loss: 0.4174 - accuracy: 0.8000 - 38ms/epoch - 2ms/step\n",
            "Epoch 438/500\n",
            "24/24 - 0s - loss: 0.4280 - accuracy: 0.7880 - 40ms/epoch - 2ms/step\n",
            "Epoch 439/500\n",
            "24/24 - 0s - loss: 0.4255 - accuracy: 0.7987 - 44ms/epoch - 2ms/step\n",
            "Epoch 440/500\n",
            "24/24 - 0s - loss: 0.4257 - accuracy: 0.7960 - 41ms/epoch - 2ms/step\n",
            "Epoch 441/500\n",
            "24/24 - 0s - loss: 0.4231 - accuracy: 0.7947 - 41ms/epoch - 2ms/step\n",
            "Epoch 442/500\n",
            "24/24 - 0s - loss: 0.4208 - accuracy: 0.8040 - 41ms/epoch - 2ms/step\n",
            "Epoch 443/500\n",
            "24/24 - 0s - loss: 0.4184 - accuracy: 0.8067 - 38ms/epoch - 2ms/step\n",
            "Epoch 444/500\n",
            "24/24 - 0s - loss: 0.4179 - accuracy: 0.8027 - 39ms/epoch - 2ms/step\n",
            "Epoch 445/500\n",
            "24/24 - 0s - loss: 0.4187 - accuracy: 0.8013 - 45ms/epoch - 2ms/step\n",
            "Epoch 446/500\n",
            "24/24 - 0s - loss: 0.4215 - accuracy: 0.8013 - 50ms/epoch - 2ms/step\n",
            "Epoch 447/500\n",
            "24/24 - 0s - loss: 0.4165 - accuracy: 0.8067 - 43ms/epoch - 2ms/step\n",
            "Epoch 448/500\n",
            "24/24 - 0s - loss: 0.4206 - accuracy: 0.7880 - 45ms/epoch - 2ms/step\n",
            "Epoch 449/500\n",
            "24/24 - 0s - loss: 0.4182 - accuracy: 0.8027 - 46ms/epoch - 2ms/step\n",
            "Epoch 450/500\n",
            "24/24 - 0s - loss: 0.4200 - accuracy: 0.7960 - 51ms/epoch - 2ms/step\n",
            "Epoch 451/500\n",
            "24/24 - 0s - loss: 0.4194 - accuracy: 0.8067 - 45ms/epoch - 2ms/step\n",
            "Epoch 452/500\n",
            "24/24 - 0s - loss: 0.4190 - accuracy: 0.8067 - 43ms/epoch - 2ms/step\n",
            "Epoch 453/500\n",
            "24/24 - 0s - loss: 0.4191 - accuracy: 0.8000 - 51ms/epoch - 2ms/step\n",
            "Epoch 454/500\n",
            "24/24 - 0s - loss: 0.4218 - accuracy: 0.8053 - 39ms/epoch - 2ms/step\n",
            "Epoch 455/500\n",
            "24/24 - 0s - loss: 0.4230 - accuracy: 0.7947 - 38ms/epoch - 2ms/step\n",
            "Epoch 456/500\n",
            "24/24 - 0s - loss: 0.4198 - accuracy: 0.8093 - 37ms/epoch - 2ms/step\n",
            "Epoch 457/500\n",
            "24/24 - 0s - loss: 0.4168 - accuracy: 0.8000 - 42ms/epoch - 2ms/step\n",
            "Epoch 458/500\n",
            "24/24 - 0s - loss: 0.4231 - accuracy: 0.8053 - 46ms/epoch - 2ms/step\n",
            "Epoch 459/500\n",
            "24/24 - 0s - loss: 0.4207 - accuracy: 0.7973 - 50ms/epoch - 2ms/step\n",
            "Epoch 460/500\n",
            "24/24 - 0s - loss: 0.4193 - accuracy: 0.7960 - 46ms/epoch - 2ms/step\n",
            "Epoch 461/500\n",
            "24/24 - 0s - loss: 0.4169 - accuracy: 0.8093 - 40ms/epoch - 2ms/step\n",
            "Epoch 462/500\n",
            "24/24 - 0s - loss: 0.4160 - accuracy: 0.8080 - 39ms/epoch - 2ms/step\n",
            "Epoch 463/500\n",
            "24/24 - 0s - loss: 0.4183 - accuracy: 0.7987 - 38ms/epoch - 2ms/step\n",
            "Epoch 464/500\n",
            "24/24 - 0s - loss: 0.4225 - accuracy: 0.8053 - 49ms/epoch - 2ms/step\n",
            "Epoch 465/500\n",
            "24/24 - 0s - loss: 0.4243 - accuracy: 0.7960 - 43ms/epoch - 2ms/step\n",
            "Epoch 466/500\n",
            "24/24 - 0s - loss: 0.4185 - accuracy: 0.7973 - 39ms/epoch - 2ms/step\n",
            "Epoch 467/500\n",
            "24/24 - 0s - loss: 0.4179 - accuracy: 0.8027 - 39ms/epoch - 2ms/step\n",
            "Epoch 468/500\n",
            "24/24 - 0s - loss: 0.4231 - accuracy: 0.7947 - 43ms/epoch - 2ms/step\n",
            "Epoch 469/500\n",
            "24/24 - 0s - loss: 0.4174 - accuracy: 0.8040 - 48ms/epoch - 2ms/step\n",
            "Epoch 470/500\n",
            "24/24 - 0s - loss: 0.4188 - accuracy: 0.8027 - 41ms/epoch - 2ms/step\n",
            "Epoch 471/500\n",
            "24/24 - 0s - loss: 0.4286 - accuracy: 0.7893 - 49ms/epoch - 2ms/step\n",
            "Epoch 472/500\n",
            "24/24 - 0s - loss: 0.4204 - accuracy: 0.8013 - 42ms/epoch - 2ms/step\n",
            "Epoch 473/500\n",
            "24/24 - 0s - loss: 0.4198 - accuracy: 0.7987 - 47ms/epoch - 2ms/step\n",
            "Epoch 474/500\n",
            "24/24 - 0s - loss: 0.4186 - accuracy: 0.8053 - 41ms/epoch - 2ms/step\n",
            "Epoch 475/500\n",
            "24/24 - 0s - loss: 0.4181 - accuracy: 0.8027 - 42ms/epoch - 2ms/step\n",
            "Epoch 476/500\n",
            "24/24 - 0s - loss: 0.4165 - accuracy: 0.8027 - 43ms/epoch - 2ms/step\n",
            "Epoch 477/500\n",
            "24/24 - 0s - loss: 0.4179 - accuracy: 0.8053 - 44ms/epoch - 2ms/step\n",
            "Epoch 478/500\n",
            "24/24 - 0s - loss: 0.4178 - accuracy: 0.8080 - 40ms/epoch - 2ms/step\n",
            "Epoch 479/500\n",
            "24/24 - 0s - loss: 0.4205 - accuracy: 0.7960 - 40ms/epoch - 2ms/step\n",
            "Epoch 480/500\n",
            "24/24 - 0s - loss: 0.4206 - accuracy: 0.8053 - 40ms/epoch - 2ms/step\n",
            "Epoch 481/500\n",
            "24/24 - 0s - loss: 0.4227 - accuracy: 0.7973 - 38ms/epoch - 2ms/step\n",
            "Epoch 482/500\n",
            "24/24 - 0s - loss: 0.4193 - accuracy: 0.8053 - 41ms/epoch - 2ms/step\n",
            "Epoch 483/500\n",
            "24/24 - 0s - loss: 0.4165 - accuracy: 0.8093 - 43ms/epoch - 2ms/step\n",
            "Epoch 484/500\n",
            "24/24 - 0s - loss: 0.4145 - accuracy: 0.8013 - 40ms/epoch - 2ms/step\n",
            "Epoch 485/500\n",
            "24/24 - 0s - loss: 0.4176 - accuracy: 0.8093 - 40ms/epoch - 2ms/step\n",
            "Epoch 486/500\n",
            "24/24 - 0s - loss: 0.4163 - accuracy: 0.8027 - 41ms/epoch - 2ms/step\n",
            "Epoch 487/500\n",
            "24/24 - 0s - loss: 0.4142 - accuracy: 0.8067 - 42ms/epoch - 2ms/step\n",
            "Epoch 488/500\n",
            "24/24 - 0s - loss: 0.4136 - accuracy: 0.8067 - 40ms/epoch - 2ms/step\n",
            "Epoch 489/500\n",
            "24/24 - 0s - loss: 0.4205 - accuracy: 0.8067 - 40ms/epoch - 2ms/step\n",
            "Epoch 490/500\n",
            "24/24 - 0s - loss: 0.4177 - accuracy: 0.7947 - 44ms/epoch - 2ms/step\n",
            "Epoch 491/500\n",
            "24/24 - 0s - loss: 0.4145 - accuracy: 0.8080 - 40ms/epoch - 2ms/step\n",
            "Epoch 492/500\n",
            "24/24 - 0s - loss: 0.4148 - accuracy: 0.8107 - 51ms/epoch - 2ms/step\n",
            "Epoch 493/500\n",
            "24/24 - 0s - loss: 0.4239 - accuracy: 0.7933 - 37ms/epoch - 2ms/step\n",
            "Epoch 494/500\n",
            "24/24 - 0s - loss: 0.4172 - accuracy: 0.8107 - 48ms/epoch - 2ms/step\n",
            "Epoch 495/500\n",
            "24/24 - 0s - loss: 0.4159 - accuracy: 0.8053 - 48ms/epoch - 2ms/step\n",
            "Epoch 496/500\n",
            "24/24 - 0s - loss: 0.4145 - accuracy: 0.8107 - 49ms/epoch - 2ms/step\n",
            "Epoch 497/500\n",
            "24/24 - 0s - loss: 0.4241 - accuracy: 0.8053 - 59ms/epoch - 2ms/step\n",
            "Epoch 498/500\n",
            "24/24 - 0s - loss: 0.4187 - accuracy: 0.8067 - 44ms/epoch - 2ms/step\n",
            "Epoch 499/500\n",
            "24/24 - 0s - loss: 0.4180 - accuracy: 0.7907 - 41ms/epoch - 2ms/step\n",
            "Epoch 500/500\n",
            "24/24 - 0s - loss: 0.4207 - accuracy: 0.8067 - 42ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12f73f3190>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "zFhJqFs-A7gA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8jdfW2CUI4B",
        "outputId": "9fe56e04-d0fe-48b5-8463-c6c602d64c12"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99573064, 0.01215196],\n",
              "       [0.44078764, 0.5391629 ],\n",
              "       [0.26513267, 0.54661614],\n",
              "       [0.71276927, 0.40002504],\n",
              "       [0.77396214, 0.35719162],\n",
              "       [0.8475793 , 0.2720049 ],\n",
              "       [0.1688377 , 0.55468667],\n",
              "       [0.7664468 , 0.43811005],\n",
              "       [0.37772766, 0.53888726],\n",
              "       [0.9054865 , 0.19415233],\n",
              "       [0.07801196, 0.5656351 ],\n",
              "       [0.49367797, 0.5411719 ],\n",
              "       [0.7321315 , 0.41680935],\n",
              "       [0.9482697 , 0.12715551],\n",
              "       [0.60280067, 0.46766984],\n",
              "       [0.65482104, 0.47470328],\n",
              "       [0.5093095 , 0.54036224],\n",
              "       [0.8264364 , 0.2682882 ],\n",
              "       [0.23962608, 0.5510312 ],\n",
              "       [0.5097253 , 0.5375188 ],\n",
              "       [0.49038556, 0.5417218 ],\n",
              "       [0.13082811, 0.56745857],\n",
              "       [0.9109336 , 0.11743605],\n",
              "       [0.7612655 , 0.5351668 ],\n",
              "       [0.70052123, 0.39061576],\n",
              "       [0.847763  , 0.5312581 ],\n",
              "       [0.96579766, 0.08874896],\n",
              "       [0.4969907 , 0.53908277],\n",
              "       [0.13926592, 0.55484927],\n",
              "       [0.11465824, 0.55895764],\n",
              "       [0.23078132, 0.55516285],\n",
              "       [0.0526551 , 0.5725944 ],\n",
              "       [0.22434211, 0.5582869 ],\n",
              "       [0.8154223 , 0.50530684],\n",
              "       [0.60913914, 0.49778098],\n",
              "       [0.06979805, 0.5683976 ],\n",
              "       [0.17244539, 0.56038386],\n",
              "       [0.44903785, 0.5438638 ],\n",
              "       [0.7338039 , 0.53178567],\n",
              "       [0.10350648, 0.56047094],\n",
              "       [0.8470043 , 0.5138964 ],\n",
              "       [0.2809025 , 0.5488336 ],\n",
              "       [0.98291945, 0.05543837],\n",
              "       [0.07054922, 0.57026595],\n",
              "       [0.11276582, 0.5651465 ],\n",
              "       [0.84613574, 0.41974932],\n",
              "       [0.6133312 , 0.49926502],\n",
              "       [0.27062804, 0.5432273 ],\n",
              "       [0.28864583, 0.55326617],\n",
              "       [0.22173378, 0.54915005],\n",
              "       [0.95535016, 0.11174858],\n",
              "       [0.9841422 , 0.04411337],\n",
              "       [0.36435863, 0.5388129 ],\n",
              "       [0.3314849 , 0.54406935],\n",
              "       [0.5443237 , 0.5059105 ],\n",
              "       [0.9852811 , 0.04003948],\n",
              "       [0.9873905 , 0.04222408],\n",
              "       [0.26622713, 0.5430844 ],\n",
              "       [0.49165657, 0.5393195 ],\n",
              "       [0.18172324, 0.55290556],\n",
              "       [0.9848659 , 0.04361796],\n",
              "       [0.8479744 , 0.3331636 ],\n",
              "       [0.07690415, 0.5737416 ],\n",
              "       [0.5629064 , 0.5141066 ],\n",
              "       [0.35155636, 0.5427879 ],\n",
              "       [0.8352954 , 0.5062789 ],\n",
              "       [0.8882139 , 0.2040104 ],\n",
              "       [0.90806293, 0.16377515],\n",
              "       [0.06123254, 0.5696531 ],\n",
              "       [0.8310993 , 0.2115925 ],\n",
              "       [0.7035459 , 0.49954706],\n",
              "       [0.4707718 , 0.5423852 ],\n",
              "       [0.43142462, 0.53507006],\n",
              "       [0.38555008, 0.5396681 ],\n",
              "       [0.23577964, 0.5540753 ],\n",
              "       [0.8904192 , 0.15123183],\n",
              "       [0.15548655, 0.55941767],\n",
              "       [0.795933  , 0.2851677 ],\n",
              "       [0.53699327, 0.47923774],\n",
              "       [0.65145427, 0.52385265],\n",
              "       [0.48875758, 0.54161966],\n",
              "       [0.25992715, 0.5504834 ],\n",
              "       [0.31008658, 0.55516434],\n",
              "       [0.12192944, 0.56903976],\n",
              "       [0.28216225, 0.5465328 ],\n",
              "       [0.10060763, 0.5609971 ],\n",
              "       [0.26820168, 0.5557601 ],\n",
              "       [0.21121782, 0.555287  ],\n",
              "       [0.67864925, 0.4847509 ],\n",
              "       [0.83581465, 0.3978759 ],\n",
              "       [0.2610533 , 0.5441465 ],\n",
              "       [0.29371357, 0.5454159 ],\n",
              "       [0.71083045, 0.38806728],\n",
              "       [0.17239422, 0.5649456 ],\n",
              "       [0.8758249 , 0.2804969 ],\n",
              "       [0.39819887, 0.5474944 ],\n",
              "       [0.602543  , 0.5362298 ],\n",
              "       [0.72556555, 0.5052899 ],\n",
              "       [0.8973093 , 0.23888963],\n",
              "       [0.3090729 , 0.55315876],\n",
              "       [0.09796962, 0.56486845],\n",
              "       [0.5986042 , 0.5083591 ],\n",
              "       [0.9888537 , 0.03554893],\n",
              "       [0.33331013, 0.54658914],\n",
              "       [0.2897902 , 0.5519568 ],\n",
              "       [0.11818701, 0.5606973 ],\n",
              "       [0.39750466, 0.5421568 ],\n",
              "       [0.96351814, 0.09377405],\n",
              "       [0.29327232, 0.5435455 ],\n",
              "       [0.647384  , 0.4858065 ],\n",
              "       [0.32087255, 0.54549485],\n",
              "       [0.7730171 , 0.31640965],\n",
              "       [0.99707294, 0.00983652],\n",
              "       [0.4675573 , 0.4948304 ],\n",
              "       [0.39580378, 0.54716915],\n",
              "       [0.52186525, 0.53740895],\n",
              "       [0.89138967, 0.23178402],\n",
              "       [0.37232536, 0.54385376],\n",
              "       [0.9310063 , 0.14426577],\n",
              "       [0.31631714, 0.55237615],\n",
              "       [0.991205  , 0.0317784 ],\n",
              "       [0.8300563 , 0.4497259 ],\n",
              "       [0.3878494 , 0.52895015],\n",
              "       [0.8524307 , 0.2723266 ],\n",
              "       [0.91154385, 0.1420913 ],\n",
              "       [0.05849859, 0.5707518 ],\n",
              "       [0.11492139, 0.5681406 ],\n",
              "       [0.27612454, 0.556034  ],\n",
              "       [0.9737801 , 0.06471819],\n",
              "       [0.677791  , 0.38072395],\n",
              "       [0.13915876, 0.56306815],\n",
              "       [0.86316013, 0.22218055],\n",
              "       [0.4190688 , 0.5173931 ],\n",
              "       [0.9539821 , 0.08327571],\n",
              "       [0.67260885, 0.4696375 ],\n",
              "       [0.31455344, 0.552815  ],\n",
              "       [0.13516882, 0.5563126 ],\n",
              "       [0.5004762 , 0.53996044],\n",
              "       [0.49500385, 0.5364545 ],\n",
              "       [0.6648921 , 0.4957071 ],\n",
              "       [0.9704299 , 0.09136909],\n",
              "       [0.36738306, 0.54072344],\n",
              "       [0.3368886 , 0.54326487],\n",
              "       [0.8947416 , 0.27334604],\n",
              "       [0.10267866, 0.57210964],\n",
              "       [0.9481306 , 0.17950568],\n",
              "       [0.40805382, 0.5455141 ],\n",
              "       [0.45120898, 0.5434981 ],\n",
              "       [0.8227276 , 0.348643  ],\n",
              "       [0.27336395, 0.5505109 ],\n",
              "       [0.67214906, 0.5303676 ],\n",
              "       [0.5078303 , 0.5267641 ],\n",
              "       [0.38204947, 0.52800983],\n",
              "       [0.13809904, 0.55501217],\n",
              "       [0.10371456, 0.5644301 ],\n",
              "       [0.16093409, 0.5537172 ],\n",
              "       [0.08600664, 0.57229716],\n",
              "       [0.93390846, 0.17225459],\n",
              "       [0.9085685 , 0.1657219 ],\n",
              "       [0.2113558 , 0.5442288 ],\n",
              "       [0.5232498 , 0.5046068 ],\n",
              "       [0.1097376 , 0.56329507],\n",
              "       [0.32303965, 0.5416123 ],\n",
              "       [0.6735018 , 0.5004409 ],\n",
              "       [0.20761722, 0.5554672 ],\n",
              "       [0.38173652, 0.54235363],\n",
              "       [0.10572401, 0.5654073 ],\n",
              "       [0.87130356, 0.5374269 ],\n",
              "       [0.3050025 , 0.54149765],\n",
              "       [0.39326966, 0.54301214],\n",
              "       [0.44243103, 0.53991103],\n",
              "       [0.89578366, 0.17963627],\n",
              "       [0.22100076, 0.55734754],\n",
              "       [0.62863845, 0.4584409 ],\n",
              "       [0.15099004, 0.5600332 ],\n",
              "       [0.9864137 , 0.03626335],\n",
              "       [0.42363372, 0.5437039 ],\n",
              "       [0.04700708, 0.5832689 ],\n",
              "       [0.6523132 , 0.49982694],\n",
              "       [0.803555  , 0.53411007],\n",
              "       [0.42850444, 0.54493153],\n",
              "       [0.8847384 , 0.54272425],\n",
              "       [0.4240822 , 0.5407212 ],\n",
              "       [0.26239833, 0.5431974 ],\n",
              "       [0.98576057, 0.03914091],\n",
              "       [0.08867553, 0.56671274],\n",
              "       [0.72013324, 0.50826687],\n",
              "       [0.15576693, 0.55633044],\n",
              "       [0.91104394, 0.18495378],\n",
              "       [0.9292418 , 0.1609391 ],\n",
              "       [0.1882951 , 0.55371517],\n",
              "       [0.14574793, 0.55945766],\n",
              "       [0.1943315 , 0.5625403 ],\n",
              "       [0.26189828, 0.5522367 ],\n",
              "       [0.88992023, 0.24046952],\n",
              "       [0.43574834, 0.5431121 ],\n",
              "       [0.7188042 , 0.5091761 ],\n",
              "       [0.91374797, 0.29761392],\n",
              "       [0.18597326, 0.5604426 ],\n",
              "       [0.7457851 , 0.47071776],\n",
              "       [0.9869683 , 0.03633749],\n",
              "       [0.32413685, 0.54363906],\n",
              "       [0.19763425, 0.5568825 ],\n",
              "       [0.19388148, 0.5592673 ],\n",
              "       [0.5807964 , 0.36887786],\n",
              "       [0.16214752, 0.55694485],\n",
              "       [0.1258266 , 0.55755216],\n",
              "       [0.5875575 , 0.48695883],\n",
              "       [0.51378053, 0.5229141 ],\n",
              "       [0.14640644, 0.5583614 ],\n",
              "       [0.320781  , 0.54193604],\n",
              "       [0.14217782, 0.5635593 ],\n",
              "       [0.83877426, 0.29285118],\n",
              "       [0.646473  , 0.54362047],\n",
              "       [0.27893722, 0.54385144],\n",
              "       [0.40009695, 0.54204303],\n",
              "       [0.6287337 , 0.49314147],\n",
              "       [0.06919321, 0.57064945],\n",
              "       [0.06176925, 0.5697938 ],\n",
              "       [0.29773062, 0.55120146],\n",
              "       [0.1346362 , 0.5595293 ],\n",
              "       [0.6886476 , 0.47530353],\n",
              "       [0.6829816 , 0.44066852],\n",
              "       [0.59869796, 0.49469993],\n",
              "       [0.5355585 , 0.47549194],\n",
              "       [0.61580825, 0.52413434],\n",
              "       [0.3014711 , 0.54957634],\n",
              "       [0.40193936, 0.53403497],\n",
              "       [0.0470973 , 0.57453364],\n",
              "       [0.32606125, 0.5490813 ],\n",
              "       [0.58387494, 0.46657303],\n",
              "       [0.13746715, 0.5551009 ],\n",
              "       [0.9842013 , 0.04585838],\n",
              "       [0.75533855, 0.35846585],\n",
              "       [0.31780928, 0.5425253 ],\n",
              "       [0.98207676, 0.05254832],\n",
              "       [0.6261219 , 0.43561146],\n",
              "       [0.4939293 , 0.5361438 ],\n",
              "       [0.93322   , 0.14344627],\n",
              "       [0.37637222, 0.54160666],\n",
              "       [0.1721729 , 0.5582079 ],\n",
              "       [0.04306155, 0.57608163],\n",
              "       [0.42757195, 0.52699465],\n",
              "       [0.14531371, 0.5540224 ],\n",
              "       [0.44511744, 0.5436158 ],\n",
              "       [0.71187323, 0.418236  ],\n",
              "       [0.05239436, 0.57268107],\n",
              "       [0.9900186 , 0.03112581],\n",
              "       [0.23630923, 0.5550407 ],\n",
              "       [0.34163684, 0.541753  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9I_pvIWBTil",
        "outputId": "87ad45a2-3795-4f2a-f43d-b000b1d33735"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.argmax(y_test,axis = 1)\n",
        "y_predict = np.argmax(y_pred,axis=1)"
      ],
      "metadata": {
        "id": "sL4Cb0yVBVTG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZtBDWokBicl",
        "outputId": "10229074-172f-49bb-87d6-e25751d403aa"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250,)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH2ahthqBkKl",
        "outputId": "20973a7f-fedd-4ecd-bc66-f37ea4b0aa5e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confumat = metrics.confusion_matrix(y_test,y_predict)"
      ],
      "metadata": {
        "id": "CSF0822jBnoP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confumat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPop6u_9Bwns",
        "outputId": "74e8c5d0-04bb-436b-af64-a157ced2db39"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 88,  37],\n",
              "       [ 20, 105]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = metrics.classification_report(y_test,y_predict)\n",
        "print()\n",
        "print('Classification Results')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvTLWvtSBxt9",
        "outputId": "c838780a-8432-45c7-f1ff-f131a554d286"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.70      0.76       125\n",
            "           1       0.74      0.84      0.79       125\n",
            "\n",
            "    accuracy                           0.77       250\n",
            "   macro avg       0.78      0.77      0.77       250\n",
            "weighted avg       0.78      0.77      0.77       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2qP-RuqMwb3s"
      },
      "execution_count": 63,
      "outputs": []
    }
  ]
}